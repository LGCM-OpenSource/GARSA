## Integração de codigos FOXCONN

## GWAS usando GCTA e Manhattam plot

# Bibliotecas necessárias

import pandas as pd
import os
import matplotlib.pyplot as plt
import subprocess
import numpy as np
import sys
import argparse
import textwrap
import shutil
import time
from scipy.stats import chisquare #1.7.3
from scipy.stats import chi2 #1.7.3
from scipy import stats #1.7.3
from numpy import genfromtxt
from assocplots.qqplot import * #0.0.2
import warnings

###############
## Functions ##
###############

tty_colors = {
	'green' : '\033[0;32m%s\033[0m',
	'yellow' : '\033[0;33m%s\033[0m',
	'red' : '\033[0;31m%s\033[0m'
}

# # or, example if wanting the ones from before with background highlighting
# tty_colors = {
#     'green' : '\x1b[6;37;42m%s\x1b[0m',
#     'red' : '\x1b[0;37;41m%s\x1b[0m'
# }

#Color texto de acordo com o "Warning"

def color_text(text, color='green'):

	if sys.stdout.isatty():
		return tty_colors[color] % text
	else:
		return text


def wprint(text):

	print(textwrap.fill(text, width=80, initial_indent="\n  ", 
		  subsequent_indent="    ", break_on_hyphens=False))

# Identificar se o arquivo de fato existe

def check_file_exists(file):

	if not os.path.exists(file):
		wprint(color_text("The specified input file '" + str(file) + "' does not seem to exist :(", "red"))
		print("\n  Exiting for now.\n")
		exit(1)


################################
### Help and argument parser ###
################################

arg_parser = argparse.ArgumentParser(description = "This is a script to GWAS analysis and plot the results with Manhattam plot", 
	epilog = "Ex. usage: script.py  ") ## AJUSTAR A DESCRIÇÃO


arg_parser.add_argument("-vcf", "--vcf_file", help = "File for GWAS analysis, required if user dont have Plink binary files")
arg_parser.add_argument("-plink", "--plink_path", help = "Path for the plink(1.9) executable, requierd with -vcf flag -- default is to look for the variable on path")
arg_parser.add_argument("-bfile", "--plink_binary_prefix", help = "Path for the plink(1.9) binary file, provide only the prefix (no extensions)")
arg_parser.add_argument("-pheno", "--phenotype_file", help = "Path for the phenotype file, this file must have FID and IID (like the .fam file) and must be separated by tab or space. Header is not mandatory", default=None)
arg_parser.add_argument("-qcovar", "--quantitative_covar", help = "Path for the quantitative covariables, e.g. PCs, age, and other continuous variables. The file must have FID and IID (like the phenotype file and .fam. The file must be separated by tab or space. Header is not mandatory", default=None)
arg_parser.add_argument("-covar", "--covar", help = "Path for the covariables, e.g. Sex and other qualitative variables. The file must have FID and IID (like the phenotype file and .fam. The file must be separated by tab or space. Header is not mandatory", default=None)
arg_parser.add_argument("-kinship", "--kinship_grm", help = "Path for the kinship grm file generated by the kinship script, if user wishes the kinship analysis can be generated with the flag --make-king")
arg_parser.add_argument("--make_king", help = "Make the kinship analysis (no correction by admixture", action="store_true")
arg_parser.add_argument("-o", "--output_folder", help = "Wanted output folder (default: current output folder)")
arg_parser.add_argument("-gcta", "--gcta_run", help = "Select gcta analysis for GWAS -- recomended for N sample < 5000", action="store_true")
arg_parser.add_argument("-BoltLmm", "--BoltLmm_run", help = "Select Bolt-lmm for GWAS -- recomended for N samples > 5000", action="store_true")
arg_parser.add_argument("-BoltLD", "--BoltLD_file", help = "Path for the Bolt-lmm LD file -- default: File provided by the BOLT-LMM distribution")
arg_parser.add_argument("--threads", help = "Number of computer threads -- default = 1", default="1")

#Se nenhum comando foi dado ao script, automaticamente é mostrado o "help"

if len(sys.argv)==1:
	arg_parser.print_help(sys.stderr)
	sys.exit(0)

##################################
### Setting starting variables ###
##################################

# getting primary script full path
path = os.path.realpath(__file__)


# getting primary script directory full path
primary_script_path = path.split("/")[:-1]
primary_script_path = "/".join(primary_script_path)


# setting database full path (assuming they are in the same directory as the primary script)
database_path = os.path.join(primary_script_path, "database")

# setting scripts path (assuming they are in the same directory as the primary script)
script_path = os.path.join(primary_script_path, "scripts")


args = arg_parser.parse_args()
args_dict = vars(arg_parser.parse_args())

vcf_file = args_dict["vcf_file"]
output_folder = args_dict["output_folder"]
plink_path = args_dict["plink_path"]
threads = args_dict["threads"]
gcta_run = args_dict["gcta_run"]
gcta_path = os.path.join(script_path, "gcta-1.94")
bfile = args_dict["plink_binary_prefix"]
pheno = args_dict["phenotype_file"]
qcovar = args_dict["quantitative_covar"]
covar = args_dict["covar"]
kinship = args_dict["kinship_grm"]
make_king = args_dict["make_king"]
bolt_path = os.path.join(script_path, "BOLT-LMM_v2.4", "bolt")
bolt_run = args_dict["BoltLmm_run"]
bolt_ld = args_dict["BoltLD_file"]

#######################
## Pre-flight checks ##
#######################
if vcf_file:

	file_path = os.path.abspath(vcf_file)

	check_file_exists(file_path)

	file_name = file_path.split("/")[-1]

	base_name = file_name.split(".")[0]

	print("Working on ",base_name)

if bfile:
	file_path = os.path.abspath(bfile)

	file_name = file_path.split("/")[-1]

	base_name = file_name

	print("Working on ",base_name)

# Se for dada uma path para output
if output_folder:

	provided_output = os.path.abspath(output_folder)

	# Criar a pasta do usuário na path providenciada
	try:
		os.mkdir(provided_output)
	except:
		print("\n")

	out_dir_path = provided_output

	print(color_text("Using specified directory for output: " + output_folder, "green"))

else:
	#Se não for dado um output, usar o diretório atual
	output_folder = os.getcwd()

	out_dir_path = output_folder

	print(color_text("No output directory specified, using current working directory: " + out_dir_path, "yellow"))

temp_files = os.path.join(out_dir_path, "tmp")
try:
	os.mkdir(temp_files)
except:
	print(color_text("tmp folder exists, will keep using it"))



print(color_text("Using "+str(threads)+" Threads"))

if not plink_path:
	plink_look_path = subprocess.run(["which", "plink1.9"], stdout=subprocess.PIPE, text=True)
	plink_path = plink_look_path.stdout.strip()

if not bolt_ld:
	bolt_ld = os.path.join(database_path, "bolt-data", "LDSCORE.1000G_EUR.tab.gz")


covar = os.path.abspath(covar)
qcovar = os.path.abspath(qcovar)
pheno = os.path.abspath(pheno)

#######################
## Starting analysis ##
#######################

#tempos de execução
exec_times = []


if vcf_file: #Se foi dado amboms VCF e path do plink o programa executa o plink para formar os arquivos binários

	plink_convertion_start = time.time()

	print(color_text("VCF file provided, starting VCF to plink BED convertion", "yellow"))

	plink_convertion_out = os.path.join(temp_files, base_name+"_converted")

	plink_convert_err = os.path.join(temp_files, "plink_convertion.err")
	plink_convert_out = os.path.join(temp_files, "plink_convertion.out")

	try:
		_try = subprocess.run([plink_path, "--vcf", vcf_file, "--keep-allele-order","--make-bed", "--out", plink_convertion_out, "--threads", threads], stdout=subprocess.PIPE, stderr=subprocess.PIPE,
			text=True)
		with open(plink_convert_err, "w") as err:
			err.write(_try.stderr)
		with open(plink_convert_out, "w") as out:
			out.write(_try.stdout)
		if _try.stderr:
			print(color_text("WARNING: Plink1.9. Check error log file "+plink_convert_err, "red"))
	except:
		print(color_text("Error on Plink1.9 execution", "red"))
		print(color_text("Path used for Plink1.9 executable = "+str(plink_path), "red"))
		print(color_text("Error log is stored in "+plink_convert_err, "yellow"))
		exit(1)

	#Nesse caso como os binários estão sendo gerados agora podemos fazer:

	bfile = plink_convertion_out

	plink_convertion_end = time.time()

	plink_convertion_time = (plink_convertion_end - plink_convertion_start)

	exec_times.append(["Plink convertion step", plink_convertion_time])

## Rodando GCTA
if gcta_run == True:

	if not os.path.exists(gcta_path):
		print(color_text("WARNING: executable for gcta not found in "+str(script_path), "yellow"))

#GCTA kinship para o usuário que achar necessário -- O input aqui vai ser o bfile, seja o gerado pelo plink ou dado pelo usuário

	if make_king == True:

		gcta_kinship_start = time.time()

		print(color_text("Startin Kinship analysis using GCTA", "yellow"))

		gcta_king_out = os.path.join(out_dir_path, base_name+"_GCTA_kinship")

		gcta_king_err = os.path.join(temp_files, "GCTA_Kinship.err")
		gcta_king_out = os.path.join(temp_files, "GCTA_Kinship.out")

		try:
			_try = subprocess.run([gcta_path, "--bfile", bfile,"--make-grm", "--out", gcta_king_out, "--thread-num", threads], stdout=subprocess.PIPE, stderr=subprocess.PIPE,
				text=True)
			with open(gcta_king_err, "w") as err:
				err.write(_try.stderr)
			with open(gcta_king_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: GCTA. Check error file "+str(gcta_king_err), "yellow"))
		except:
			print(color_text("ERROR on GCTA", "red"))
			print(color_text("Check error log on "+str(gcta_king_err), "yellow"))
			exit(1)

		kinship = gcta_king_out

		gcta_kinship_end = time.time()

		gcta_kinship_time = (gcta_kinship_end - gcta_kinship_start)

		exec_times.append(["Kinship_GCTA", gcta_kinship_time])

	#Após organizar tudo, precisamos dos binários (fornecidos ou gerados), kinship (fornecido, do nosso script em R ou gerado aqui), dos fenótipos dados pelo usuário e das covariaveis também dado pelo usuário
	gwas_start = time.time()
	print(color_text("Starting the GWAS regression using Linear Mixed Model (LMM)", "yellow"))

	if args_dict["quantitative_covar"] is not None and args_dict["covar"] is not None: #Se foi fornecido ambos covar e qcovar
		
		print(color_text("Using covar and qcovar for regression", "yellow"))

		gwas_out = os.path.join(out_dir_path, base_name+"_GCTA_qcovar_covar_GWAS")
		gcta_qcov_cov_err = os.path.join(temp_files, "gcta_qcov_cov.err")
		gcta_qcov_cov_out = os.path.join(temp_files, "gcta_qcov_cov.out")

		try:
			_try = subprocess.run([gcta_path, "--mlma", "--bfile", bfile, "--pheno", pheno, "--qcovar", qcovar, "--covar", covar, "--grm", kinship, "--out", gwas_out,"--thread-num", threads],
				stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(gcta_qcov_cov_err, "w") as err:
				err.write(_try.stderr)
			with open(gcta_qcov_cov_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: GCTA. Check error file "+str(gcta_qcov_cov_err), "yellow"))
		except:
			print(color_text("ERROR on GCTA", "red"))
			print(color_text("Check error log on "+str(gcta_king_err), "yellow"))
			exit(1)

	if args_dict["quantitative_covar"] is None and args_dict["covar"] is not None: #Fornecendo apenas o arquivo covar

		print(color_text("Using only covar for regression", "yellow"))

		gwas_out = os.path.join(out_dir_path, base_name+"_covar_GWAS")
		gcta_cov_err = os.path.join(temp_files, "gcta_cov.err")
		gcta_cov_out = os.path.join(temp_files, "gcta_cov.out")

		try:
			_try = subprocess.run([gcta_path, "--mlma", "--bfile", bfile, "--pheno", pheno, "--covar", covar, "--grm", kinship, "--out", gwas_out,"--thread-num", threads],
				stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(gcta_cov_err, "w") as err:
				err.write(_try.stderr)
			with open(gcta_cov_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: GCTA. Check error file "+str(gcta_cov_err), "yellow"))
		except:
			print(color_text("ERROR on GCTA", "red"))
			print(color_text("Check error log on "+str(gcta_king_err), "yellow"))
			exit(1)


	if args_dict["quantitative_covar"] is not None and args_dict["covar"] is None:#Fornecendo apenas o arquivo qcovar

		print(color_text("Using only qcovar for regresion", "yellow"))
		gwas_out = os.path.join(out_dir_path, base_name+"_qcovar_GWAS")
		gcta_qcov_err = os.path.join(temp_files, "gcta_qov.err")
		gcta_qcov_out = os.path.join(temp_files, "gcta_qov.out")

		try:
			_try = subprocess.run([gcta_path, "--mlma", "--bfile", bfile, "--pheno", pheno, "--qcovar", qcovar, "--grm", kinship, "--out", gwas_out,"--thread-num", threads],
				stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(gcta_qcov_err, "w") as err:
				err.write(_try.stderr)
			with oepn(gcta_qcov_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: GCTA. Check error file "+str(gcta_qcov_err), "yellow"))
		except:
			print(color_text("ERROR on GCTA", "red"))
			print(color_text("Check error log on "+str(gcta_king_err), "yellow"))
			exit(1)

if bolt_run == True:

	if not os.path.exists(bolt_path):
		print(color_text("WARNING: executable for bolt-lmm not found in "+str(script_path), "yellow"))

	total_n_of_SNPS = len(genfromtxt(bfile+".bim", delimiter=' '))

	gwas_start = time.time()
	print(color_text("Starting the BOLT GWAS regression using Linear Mixed Model (LMM)", "yellow"))

	if args_dict["quantitative_covar"] is not None and args_dict["covar"] is not None: #Se foi fornecido ambos covar e qcovar
		
		print(color_text("Using covar and qcovar for regression", "yellow"))

		bolt_covars = os.path.join(temp_files, "bolt_covars.tsv")

		gwas_out = os.path.join(out_dir_path, base_name+"_BOLT_qcovar_covar_GWAS")


		#Os arquivos de fenótipo contém 3 colunas -- FID IID e PHENO

		get_pheno_col = pd.read_csv(pheno, dtype="str",sep=None, engine="python", header=None)

		pheno_col = get_pheno_col.columns.tolist()[-1]

		
		## Agora podemos seguir em frente e a partir dos arquivos fornecidos gerar o restante dos comandos

		get_covars_cols = pd.read_csv(covar, dtype="str",sep=None, engine="python", header=None)

		covar_cols = get_covars_cols.columns.tolist()

		get_covars_cols.rename(columns={covar_cols[0]: "FID", covar_cols[1]: "IID"}, inplace=True)

		covars_data = get_covars_cols.columns.tolist()[2:]

		covars_command = ["--covarCol="+str(x) for x in covars_data] #Lista de comandos para covars pronto!

		## Por fim pegamos os qcovars

		get_qcovars_cols = pd.read_csv(qcovar, dtype="str",sep=None, engine="python")

		qcovars_data = get_qcovars_cols.columns.tolist()[2:]

		qcovars_command = ["--qCovarCol="+str(x) for x in qcovars_data]

		bolt_covars_df = pd.merge(get_covars_cols, get_qcovars_cols, on=["FID", "IID"], how="left")

		bolt_covars_df.to_csv(bolt_covars, index=False, sep="\t")

		## Como a quantidade de valores de covar e qcovars pode ser variavel faremos primeiro uma lista com todos os valores que são fixos
		## bfile, phenoFile, phenoCol e covarFile precisam estar presentes -- Lembrando que o fenótipo é apenas 1 e permite que fique "Fixo" no código

		start_command = [bolt_path, "--bfile="+str(bfile), "--maxModelSnps="+str(total_n_of_SNPS),"--numThreads="+str(threads), "--statsFile="+str(gwas_out)+".stats",
		"--covarUseMissingIndic",
		"--LDscoresFile="+str(bolt_ld),"--lmm",
		"--phenoFile="+str(pheno), 
		"--phenoCol="+str(pheno_col),
		"--covarFile="+str(bolt_covars)]

		## Agora vamos gerar a lista com os comandos finais

		final_commands = start_command + covars_command + qcovars_command

		with open("teste", "w") as f:
			for i in final_commands:
				f.write(i+"\n")

		bolt_qvocar_covar_err = os.path.join(temp_files, "bolt_qvocar_covar.err")
		bolt_qvocar_covar_out = os.path.join(temp_files, "bolt_qvocar_covar.out")

		try:
			_try = subprocess.run(final_commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(bolt_qvocar_covar_err, "w") as err:
				err.write(_try.stderr)
			with open(bolt_qvocar_covar_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: BOLT-LMM. Check error file "+str(bolt_qvocar_covar_err), "yellow"))
		except:
			print(color_text("ERROR on BOLT-LMM execution", "red"))
			print(color_text("For more details check the "+str(bolt_qvocar_covar_err)+" file", "yellow"))


	if args_dict["quantitative_covar"] is None and args_dict["covar"] is not None: #Fornecendo apenas o arquivo covar

		print(color_text("Using only covar for regression", "yellow"))

		gwas_out = os.path.join(out_dir_path, base_name+"_BOLT_covar_GWAS")

		#Os arquivos de fenótipo contém 3 colunas -- FID IID e PHENO

		get_pheno_col = pd.read_csv(pheno, dtype="str",sep=None, engine="python", header=None)

		pheno_col = get_pheno_col.columns.tolist()[-1]

		start_command = [bolt_path, "--bfile="+str(bfile), "--maxModelSnps="+str(total_n_of_SNPS),"--numThreads="+str(threads), "--statsFile="+str(gwas_out)+".stats",
		"--covarUseMissingIndic",
		"--LDscoresFile="+str(bolt_ld),"--lmm",
		"--phenoFile="+str(pheno), 
		"--phenoCol="+str(pheno_col),
		"--covarFile="+str(covar)]

		## Nesse caso, foi fornecido apenas o arquivo de covars

		get_covars_cols = pd.read_csv(covar, dtype="str",sep=None, engine="python", header=None)

		covars_data = get_covars_cols.columns.tolist()[2:]

		covars_command = ["--covarCol="+str(x) for x in covars_data] #Lista de comandos para covars pronto!
	

		final_commands = start_command + covars_command

		bolt_qvocar_covar_err = os.path.join(temp_files, "bolt_qvocar_covar.err")
		bolt_qvocar_covar_out = os.path.join(temp_files, "bolt_qvocar_covar.out")

		try:
			_try = subprocess.run(final_commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(bolt_qvocar_covar_err, "w") as err:
				err.write(_try.stderr)
			with open(bolt_qvocar_covar_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: BOLT-LMM. Check error file "+str(bolt_qvocar_covar_err), "yellow"))
		except:
			print(color_text("ERROR on BOLT-LMM execution", "red"))
			print(color_text("For more details check the "+str(bolt_qvocar_covar_err)+" file", "yellow"))

	if args_dict["quantitative_covar"] is not None and args_dict["covar"] is None:#Fornecendo apenas o arquivo qcovar

		print(color_text("Using only qcovar for regresion", "yellow"))

		gwas_out = os.path.join(out_dir_path, base_name+"_BOLT_qcovar_GWAS")


		#Os arquivos de fenótipo contém 3 colunas -- FID IID e PHENO

		get_pheno_col = pd.read_csv(pheno, dtype="str",sep=None, engine="python", heade=None)

		pheno_col = get_pheno_col.columns.tolist()[-1]

		start_command = [bolt_path, "--bfile="+str(bfile), "--maxModelSnps="+str(total_n_of_SNPS),"--numThreads="+str(threads), "--statsFile="+str(gwas_out)+".stats" ,
		"--covarUseMissingIndic",
		"--LDscoresFile="+str(bolt_ld),"--lmm",
		"--phenoFile="+str(pheno), 
		"--phenoCol="+str(pheno_col),
		"--covarFile="+str(covar)]

		## Nesse caso, foi fornecido apenas o arquivo de qcovars

		get_qcovars_cols = pd.read_csv(qcovar, dtype="str",sep=None, engine="python")

		qcovars_data = get_qcovars_cols.columns.tolist()[2:]

		qcovars_command = ["--qCovarCol="+str(x) for x in qcovars_data]

		final_commands = start_command + qcovars_command

		bolt_qvocar_covar_err = os.path.join(temp_files, "bolt_qvocar_covar.err")
		bolt_qvocar_covar_out = os.path.join(temp_files, "bolt_qvocar_covar.out")

		try:
			_try = subprocess.run(final_commands, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
			with open(bolt_qvocar_covar_err, "w") as err:
				err.write(_try.stderr)
			with open(bolt_qvocar_covar_out, "w") as out:
				out.write(_try.stdout)
			if _try.stderr:
				print(color_text("WARNING: BOLT-LMM. Check error file "+str(bolt_qvocar_covar_err), "yellow"))
		except:
			print(color_text("ERROR on BOLT-LMM execution", "red"))
			print(color_text("For more details check the "+str(bolt_qvocar_covar_err)+" file", "yellow"))

gwas_end = time.time()

gwas_time = (gwas_end - gwas_start)

exec_times.append(["GWAS regression", gwas_time])


#Agora vamos corrigir os pvalues usando https://doi.org/10.1111/jbg.12419 como referencia para os calculos

if gcta_run:

	gc_start = time.time()

	print(color_text("Starting p-value correction using genomic inflation"))

	gwas_output_summary = gwas_out+".mlma"

	gwas_summary = pd.read_csv(gwas_output_summary, sep="\t")

	#Gerar coluna com 1-pvalue

	gwas_summary["1-pvalue"] = 1-gwas_summary["p"]

	#Calcular o Chi2 para cada pvalue (agora 1-pvalue) com 1 grau de liberdade

	print(color_text("Calculating Chi2 for all variants -- This may take a while", "yellow"))

	gwas_summary["Chi2"] = gwas_summary["1-pvalue"].apply(lambda x: chi2.ppf(x,1))

	#Agora vamos tirar a mediana dos valore de Chi2

	print(color_text("Calculating median of Chi2 and genomic inflation for each chromosome", "yellow"))

	gen_infl_list = [] #Lista que vai conter todos os valores de genomic inflation
	for i in range(1,23):
		chr_temp = gwas_summary[gwas_summary["Chr"] == i]
		median = chr_temp["Chi2"].median()
		gen_infl = median/chi2.ppf(0.5,1)
		gen_infl_list.append([gen_infl, i])
		print("The inflation found for chr "+str(i)+" is "+str(gen_infl))

	temp_df = pd.DataFrame(gen_infl_list, columns=["genomic_inf_by_chr", "Chr"]) #Dataframe criado para conter os resultados de genomic inflation

	print(color_text("Adjusting p-value using the genomic inflation", "yellow"))

	gwas_adjusted = pd.merge(gwas_summary, temp_df, on="Chr", how="left")

	gwas_adjusted["Corrected_pvalues"] = gwas_adjusted["p"]/gwas_adjusted["genomic_inf_by_chr"]

	print(color_text("Plotting the data with Manhattam and QQ plots", "yellow"))

	#Primeira coisa é fazer a transformação para -log10 de pvalue

	gwas_adjusted["-log10_pvalue"] = -np.log10(gwas_adjusted["Corrected_pvalues"])

	#Salvar a tabela contendo os pvalues ajustados

	gwas_pvalue_adjusted = os.path.join(out_dir_path, "GWAS_summary_adjusted_pvalues.csv")

	print(color_text("Saving the GWAS table with adjusted pvalue as "+gwas_pvalue_adjusted))

	gwas_adjusted.to_csv(gwas_pvalue_adjusted, index=False)

	gc_end = time.time()

	gc_time = (gc_end - gc_start)

	exec_times.append(["Genomic inflation corretion", gc_time])

if bolt_run:

	gwas_output_summary = gwas_out+".stats"

	gc_start = time.time()

	print(color_text("Starting p-value correction using genomic inflation"))

	gwas_summary = pd.read_csv(gwas_output_summary, sep="\t")

	#Gerar coluna com 1-pvalue

	p_value_index = bolt.iloc[:,[-1]].columns.tolist()[0]


	gwas_summary["1-pvalue"] = 1-gwas_summary.iloc[:,-1]

	#Calcular o Chi2 para cada pvalue (agora 1-pvalue) com 1 grau de liberdade

	print(color_text("Calculating Chi2 for all variants -- This may take a while", "yellow"))

	gwas_summary["Chi2"] = gwas_summary["1-pvalue"].apply(lambda x: chi2.ppf(x,1))

	#Agora vamos tirar a mediana dos valore de Chi2

	print(color_text("Calculating median of Chi2 and genomic inflation for each chromosome", "yellow"))

	gen_infl_list = [] #Lista que vai conter todos os valores de genomic inflation
	for i in range(1,23):
		chr_temp = gwas_summary[gwas_summary["CHR"] == i]
		median = chr_temp["Chi2"].median()
		gen_infl = median/chi2.ppf(0.5,1)
		gen_infl_list.append([gen_infl, i])

		print("The inflation found for chr"+str(i)+" is "+str(gen_infl))

	temp_df = pd.DataFrame(gen_infl_list, columns=["genomic_inf_by_chr", "CHR"]) #Dataframe criado para conter os resultados de genomic inflation

	print(color_text("Adjusting p-value using the genomic inflation", "yellow"))

	gwas_adjusted = pd.merge(gwas_summary, temp_df, on="CHR", how="left")

	gwas_adjusted["Corrected_pvalues"] = gwas_adjusted["p"]/gwas_adjusted["genomic_inf_by_chr"]

	print(color_text("Plotting the data with Manhattam and QQ plots", "yellow"))

	#Primeira coisa é fazer a transformação para -log10 de pvalue

	gwas_adjusted["-log10_pvalue"] = -np.log10(gwas_adjusted["Corrected_pvalues"])

	#Salvar a tabela contendo os pvalues ajustados

	gwas_pvalue_adjusted = os.path.join(out_dir_path, "GWAS_summary_adjusted_pvalues.csv")

	print(color_text("Saving the GWAS table with adjusted pvalue as "+gwas_pvalue_adjusted))

	gwas_adjusted.to_csv(gwas_pvalue_adjusted, index=False)

	gc_end = time.time()

	gc_time = (gc_end - gc_start)

	exec_times.append(["Genomic inflation corretion", gc_time])
#Start plot

plot_start = time.time()

print(color_text("Plotting data", "yellow"))

gwas_adjusted["ind"] = range(len(gwas_adjusted))

if gcta_run:

	gwas_adjusted_group = gwas_adjusted.groupby(("Chr")) #Group by serve para segregar o plot por cromossomo

if bolt_run:
	gwas_adjusted_group = gwas_adjusted.groupby(("CHR"))
##PLOTING##
print(color_text("Plotting Manhatam Plot"))
#Para isso vamos precisar de algumas bibliotecas extras

fig = plt.figure(figsize=(20, 8)) # Set the figure size
ax = fig.add_subplot(111)

colors = ['cornflowerblue','lightskyblue']
x_labels = []
x_labels_pos = []


for num, (name, group) in enumerate(gwas_adjusted_group):
	group.plot(kind='scatter', x='ind', y='-log10_pvalue',color=colors[num % len(colors)], ax=ax)
	x_labels.append(name)
	x_labels_pos.append((group['ind'].iloc[-1] - (group['ind'].iloc[-1] - group['ind'].iloc[0])/2))
ax.set_xticks(x_labels_pos)
ax.set_xticklabels(x_labels, fontsize=12)

# x axis label
ax.set_xlabel('Chromosome')

#Linha threshold
plt.axhline(y = -np.log10(5e-8), color = 'b', linestyle = '--')

#Save to Output

plot_manhattam_out = os.path.join(out_dir_path, "Manhattam_plot_"+base_name+".png")

plt.savefig(plot_manhattam_out, dpi=300)


#QQ plot

# gwas_adjusted = gwas_adjusted[gwas_adjusted["Corrected_pvalues"] != 0]
print(color_text("Plotting QQ Plot"))

try:
	with warnings.catch_warning():
		warnings.simplefilter("ignore")
	fig = plt.figure(figsize=(10,10))
	qqplot([gwas_adjusted["Corrected_pvalues"]],
		["p-values"],
		color=['b'], 
		fill_dens=[0.2], 
		error_type='theoretical', 
		distribution='beta',
		title='')
	plt.legend(fontsize=20)

	#QQ output

	qq_output = os.path.join(out_dir_path, "QQ_plot"+base_name+".pdf")

	plt.savefig(qq_output, dpi=300)
except:
	print(color_text("WARNING: QQ plot, with the GWAS_summary_adjusted_pvalues.csv the plot can be manualy plotted if not found in output folder", "yellow"))

plot_end = time.time()

plot_time = (plot_end - plot_start)

exec_times.append(["Plots", plot_time])

#Salvando os tempos

exec_times_df = pd.DataFrame.from_records(exec_times, columns=["Task", "Time"])

exec_out = os.path.join(out_dir_path,base_name+"_GWAS_execution_times.tsv")

exec_times_df.to_csv(exec_out, index=False, sep="\t")


